{"componentChunkName":"component---src-components-template-js","path":"/agility","result":{"data":{"markdownRemark":{"html":"<h2 id=\"4-abstract-demand-oriented-schema\" style=\"position:relative;\"><a href=\"#4-abstract-demand-oriented-schema\" aria-label=\"4 abstract demand oriented schema permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. Abstract, Demand-Oriented Schema</h2>\n<blockquote>\n<p>The schema should act as an <strong>abstraction layer</strong> that provides flexibility to consumers while hiding service implementation details.</p>\n</blockquote>\n<p>A large part of the value of GraphQL lies in providing an abstraction between services and consumers, so the schema should not be tightly coupled either to particular service implementations or to particular consumers as they exist today. By keeping implementation details out of the schema, it should be possible to refactor the services that implement the graph – for example, transitioning from a monolith to microservices, or changing the language in which a service is implemented – without disturbing apps in the field. Likewise, the schema shouldn't be tightly coupled to the way that particular apps fetch data. It should be possible to write new apps with minimal changes to the graph if their functionality is similar to that of existing apps.</p>\n<p>To accomplish this, use the standard of a <strong>demand-oriented</strong> schema: a schema focused on providing a great developer experience to an app developer building a new feature against the existing graph. Aiming for this standard will help prevent the graph from becoming coupled to a service implementation that could change in the future, and help increase the reuse value of each field added to the graph.</p>\n<h2 id=\"5-use-an-agile-approach-to-schema-development\" style=\"position:relative;\"><a href=\"#5-use-an-agile-approach-to-schema-development\" aria-label=\"5 use an agile approach to schema development permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5. Use an Agile Approach to Schema Development</h2>\n<blockquote>\n<p>The schema should be <strong>built incrementally</strong> based on actual requirements and <strong>evolve smoothly</strong> over time.</p>\n</blockquote>\n<p>It may be tempting to try to define, ahead of time, the “perfect schema” for all of your organization's data. Rather, what really makes a schema valuable is the degree to which it follows actual user requirements, which are never known perfectly up front and are constantly changing. The true path to the “perfect schema” is to make it easy for the graph to evolve in response to actual needs.</p>\n<p>Fields shouldn't be added to the schema speculatively. Ideally, each field should be added only in response to a concrete need by a consumer for additional functionality, while being designed for maximum reuse by other consumers that have similar needs.</p>\n<p>Updating the graph should be a continuous process. Rather than releasing a new “version” of the graph periodically, such as every 6 or 12 months, it should be possible to change the graph many times a day if necessary. New fields can be added at any time. To remove a field, first deprecate it, and then remove it when consumers are no longer using it. The schema registry enables this agile evolution of the graph, together with processes and tooling that keep everyone aware of changes that could affect them. This ensures that only fully vetted changes can go into production.</p>\n<h2 id=\"6-iteratively-improve-performance\" style=\"position:relative;\"><a href=\"#6-iteratively-improve-performance\" aria-label=\"6 iteratively improve performance permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>6. Iteratively Improve Performance</h2>\n<blockquote>\n<p>Performance management should be a <strong>continuous, data-driven process</strong>, adapting smoothly to changing query loads and service implementations.</p>\n</blockquote>\n<p>The graph layer is the right place to hold the conversation about performance and capacity that always must occur between services teams and the app developers that consume their services. This conversation should be an ongoing process that gives service developers continuous and proactive visibility into what consumers intend to do with their services.</p>\n<p>Rather than optimizing every possible use of the graph, the focus should be on supporting the actual query shapes that are needed in production. Tooling should extract proposed new query shapes and surface them, before they go into production, to all affected service teams with latency requirements and projected query volume. Once the query is in production, its performance should be continuously monitored. If this principle is followed, problems should be easy to track back to the service that is not behaving as expected.</p>\n<h2 id=\"7-use-graph-metadata-to-empower-developers\" style=\"position:relative;\"><a href=\"#7-use-graph-metadata-to-empower-developers\" aria-label=\"7 use graph metadata to empower developers permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>7. Use Graph Metadata to Empower Developers</h2>\n<blockquote>\n<p>Developers should be equipped with <strong>rich awareness of the graph</strong> throughout the entire development process.</p>\n</blockquote>\n<p>A major part of GraphQL's value is the massive productivity boost that it gives to developers. To maximize this boost, a developer's tooling should give them ubiquitous awareness of the graph, threaded through all of the tools that they use throughout the entire development lifecycle.</p>\n<p>Whenever a developer is doing work that relates to managing data or connecting to services, their tooling should put live information about the graph at their fingertips. This information should always be up-to-date and the tooling should be highly intelligent, applying graph awareness to the situation at hand in helpful and powerful ways. When done properly, not only does developer productivity and happiness increase, but GraphQL becomes the fabric that connects the frontend and backend teams, enabling seamless conversations throughout the development lifecycle.</p>\n<p>Some practical examples of the power of data-graph-aware tooling include:</p>\n<ul>\n<li>Developers can enjoy live documentation of all available graph data and services, right in their editor and always up-to-date.</li>\n<li>Information about deprecated fields can be broadcast into the editors of developers using those fields, together with suggested alternatives</li>\n<li>The estimated cost of a query (in latency or server resources) can be shown to a developer as they're typing it, based on live production data.</li>\n<li>The operations team can trace load on backend services back to a particular app, version, feature, and even line of code, giving them full visibility into how developers are using their service.</li>\n<li>When a service developer makes a change to their schema, the impact of that change can automatically be determined as part of the continuous integration process. If the change would break existing clients (as determined by replaying recent production usage), then the service developer can determine the precise clients, versions, and developers that will be affected.</li>\n<li>As app developers are building features, the new queries that power those features can be extracted from their code and shared with the operations team. With this awareness, the operations team can proactively provision the needed capacity and interject early in the development process if the query can't be approved at the intended scale.</li>\n<li>When apps are developed in a typed language like TypeScript, Java, or Swift, type information can be propagated all the way from service type declarations through every line of code in the app, ensuring fullstack type correctness and instant feedback on errors.</li>\n</ul>\n<!-- end -->","frontmatter":{"path":"/agility","title":"Agility Principles","description":"Rapidly rolling out the graph and continuously adapting it to changing needs","order":2,"image":{"publicURL":"/principled-graphql/static/e2e89dc4c42aaf0674d72279db47f6f5/agility.png"}}},"allMarkdownRemark":{"edges":[{"node":{"excerpt":"Principled GraphQL GraphQL, despite the name, isn't simply a query language. It's a comprehensive solution to the problem of connecting…","tableOfContents":"<ul>\n<li><a href=\"/principled-graphql//#principled-graphql\">Principled GraphQL</a></li>\n</ul>","headings":[{"depth":1,"value":"Principled GraphQL"}],"frontmatter":{"path":"/","title":"","description":null,"order":0,"image":null}}},{"node":{"excerpt":"1. One Graph Your company should have one unified graph, instead of multiple graphs created by each team. By having one graph, you maximize the value of GraphQL: More data and services can be accessed from a single query Code, queries, skills, and experience are portable across teams One central catalog of all available data that all graph users can look to Implementation cost is minimized, because graph implementation work isn't duplicated Central management of the graph – for example, unified access control policies – becomes possible When teams create their own individual graphs without coordinating their work, it is all but inevitable that their graphs will begin to overlap, adding the same data to the graph in incompatible ways. At best, this is costly to rework; at worst, it creates chaos. This principle should be followed as early in a company's graph adoption journey as possible. 2. Federated Implementation Though there is only one graph, the implementation of that graph should be federated across multiple teams. Monolithic architectures are difficult to scale without highly specialized infrastructure, and graphs are no exception. Instead of implementing an organization's entire graph layer in a single codebase, responsibility for defining and implementing the graph should be divided across multiple teams. Each team should be responsible for maintaining the portion of the schema that exposes their data and services, while having the flexibility to develop independently and operate on their own release cycle. This maintains the value of a single, unified view of the graph, while keeping development efforts across the company decoupled. 3. Track the Schema in a Registry There should be a single source of truth for registering and tracking the graph. Just like it's important to track source code in a version control system, it's important to track the definition of your graph in a schema registry. There should be a single schema registry for your company that is the authoritative definition of the graph, rather than relying on whatever processes are running at the moment or whatever code is checked in on a developer's laptop. Like a source control system, the schema registry should store the history of changes to the graph and who made them, and it should understand the concept of multiple versions of the graph (for example, staging and production, or different development branches) in a way that parallels the software development process. The schema registry should become the central hub of the system, powering developer tools, workflows, or any business processes that would benefit from awareness of the graph and any actual or proposed changes to it.","tableOfContents":"<ul>\n<li><a href=\"/principled-graphql/integrity/#1-one-graph\">1. One Graph</a></li>\n<li><a href=\"/principled-graphql/integrity/#2-federated-implementation\">2. Federated Implementation</a></li>\n<li><a href=\"/principled-graphql/integrity/#3-track-the-schema-in-a-registry\">3. Track the Schema in a Registry</a></li>\n</ul>","headings":[{"depth":2,"value":"1. One Graph"},{"depth":2,"value":"2. Federated Implementation"},{"depth":2,"value":"3. Track the Schema in a Registry"}],"frontmatter":{"path":"/integrity","title":"Integrity Principles","description":"Ensuring that the graph is well-defined, stable, and consistent","order":1,"image":{"publicURL":"/principled-graphql/static/3761fae0b2b8c8c13d2ce5de2a6c7951/integrity.png"}}}},{"node":{"excerpt":"4. Abstract, Demand-Oriented Schema The schema should act as an abstraction layer that provides flexibility to consumers while hiding service implementation details. A large part of the value of GraphQL lies in providing an abstraction between services and consumers, so the schema should not be tightly coupled either to particular service implementations or to particular consumers as they exist today. By keeping implementation details out of the schema, it should be possible to refactor the services that implement the graph – for example, transitioning from a monolith to microservices, or changing the language in which a service is implemented – without disturbing apps in the field. Likewise, the schema shouldn't be tightly coupled to the way that particular apps fetch data. It should be possible to write new apps with minimal changes to the graph if their functionality is similar to that of existing apps. To accomplish this, use the standard of a demand-oriented schema: a schema focused on providing a great developer experience to an app developer building a new feature against the existing graph. Aiming for this standard will help prevent the graph from becoming coupled to a service implementation that could change in the future, and help increase the reuse value of each field added to the graph. 5. Use an Agile Approach to Schema Development The schema should be built incrementally based on actual requirements and evolve smoothly over time. It may be tempting to try to define, ahead of time, the “perfect schema” for all of your organization's data. Rather, what really makes a schema valuable is the degree to which it follows actual user requirements, which are never known perfectly up front and are constantly changing. The true path to the “perfect schema” is to make it easy for the graph to evolve in response to actual needs. Fields shouldn't be added to the schema speculatively. Ideally, each field should be added only in response to a concrete need by a consumer for additional functionality, while being designed for maximum reuse by other consumers that have similar needs. Updating the graph should be a continuous process. Rather than releasing a new “version” of the graph periodically, such as every 6 or 12 months, it should be possible to change the graph many times a day if necessary. New fields can be added at any time. To remove a field, first deprecate it, and then remove it when consumers are no longer using it. The schema registry enables this agile evolution of the graph, together with processes and tooling that keep everyone aware of changes that could affect them. This ensures that only fully vetted changes can go into production. 6. Iteratively Improve Performance Performance management should be a continuous, data-driven process, adapting smoothly to changing query loads and service implementations. The graph layer is the right place to hold the conversation about performance and capacity that always must occur between services teams and the app developers that consume their services. This conversation should be an ongoing process that gives service developers continuous and proactive visibility into what consumers intend to do with their services. Rather than optimizing every possible use of the graph, the focus should be on supporting the actual query shapes that are needed in production. Tooling should extract proposed new query shapes and surface them, before they go into production, to all affected service teams with latency requirements and projected query volume. Once the query is in production, its performance should be continuously monitored. If this principle is followed, problems should be easy to track back to the service that is not behaving as expected. 7. Use Graph Metadata to Empower Developers Developers should be equipped with rich awareness of the graph throughout the entire development process. A major part of GraphQL's value is the massive productivity boost that it gives to developers. To maximize this boost, a developer's tooling should give them ubiquitous awareness of the graph, threaded through all of the tools that they use throughout the entire development lifecycle. Whenever a developer is doing work that relates to managing data or connecting to services, their tooling should put live information about the graph at their fingertips. This information should always be up-to-date and the tooling should be highly intelligent, applying graph awareness to the situation at hand in helpful and powerful ways. When done properly, not only does developer productivity and happiness increase, but GraphQL becomes the fabric that connects the frontend and backend teams, enabling seamless conversations throughout the development lifecycle. Some practical examples of the power of data-graph-aware tooling include: Developers can enjoy live documentation of all available graph data and services, right in their editor and always up-to-date. Information about deprecated fields can be broadcast into the editors of developers using those fields, together with suggested alternatives The estimated cost of a query (in latency or server resources) can be shown to a developer as they're typing it, based on live production data. The operations team can trace load on backend services back to a particular app, version, feature, and even line of code, giving them full visibility into how developers are using their service. When a service developer makes a change to their schema, the impact of that change can automatically be determined as part of the continuous integration process. If the change would break existing clients (as determined by replaying recent production usage), then the service developer can determine the precise clients, versions, and developers that will be affected. As app developers are building features, the new queries that power those features can be extracted from their code and shared with the operations team. With this awareness, the operations team can proactively provision the needed capacity and interject early in the development process if the query can't be approved at the intended scale. When apps are developed in a typed language like TypeScript, Java, or Swift, type information can be propagated all the way from service type declarations through every line of code in the app, ensuring fullstack type correctness and instant feedback on errors.","tableOfContents":"<ul>\n<li><a href=\"/principled-graphql/agility/#4-abstract-demand-oriented-schema\">4. Abstract, Demand-Oriented Schema</a></li>\n<li><a href=\"/principled-graphql/agility/#5-use-an-agile-approach-to-schema-development\">5. Use an Agile Approach to Schema Development</a></li>\n<li><a href=\"/principled-graphql/agility/#6-iteratively-improve-performance\">6. Iteratively Improve Performance</a></li>\n<li><a href=\"/principled-graphql/agility/#7-use-graph-metadata-to-empower-developers\">7. Use Graph Metadata to Empower Developers</a></li>\n</ul>","headings":[{"depth":2,"value":"4. Abstract, Demand-Oriented Schema"},{"depth":2,"value":"5. Use an Agile Approach to Schema Development"},{"depth":2,"value":"6. Iteratively Improve Performance"},{"depth":2,"value":"7. Use Graph Metadata to Empower Developers"}],"frontmatter":{"path":"/agility","title":"Agility Principles","description":"Rapidly rolling out the graph and continuously adapting it to changing needs","order":2,"image":{"publicURL":"/principled-graphql/static/e2e89dc4c42aaf0674d72279db47f6f5/agility.png"}}}},{"node":{"excerpt":"8. Access and Demand Control Grant access to the graph on a per-client basis, and manage what and how clients can access it. Authorization in a graph has two equally important aspects: access control, which dictates which objects and fields a user is allowed to access, and demand control, which dictates how (and how much) the user is allowed to access those resources. While access control is often talked about, attention also needs to be given to demand control, since it is critical in any production deployment of GraphQL. It is a mistake to allow users to perform any possible query regardless of cost, with no ability to manage its impact on production systems. Both access and demand control must be performed with full awareness of the semantics and performance of the graph. It's not sufficient to limit a user to particular number of queries per minute without an analysis of the queries actually being sent, as a query could access a wide universe of services and the cost of a query can vary over multiple orders of magnitude. Authentication in a graph also has two aspects: the app that is requesting the operation, and the person that is using the app. While access control may center on the person using the app, proper demand control depends at least as much on per-app controls as it does on per-person controls, as it is the developer of the app, not the user of the app, that is responsible for the particular query shapes that the app uses to do its job. Best practices for demand control include: When untrusted users are accessing production systems, they should only send queries that have been preregistered by the authenticated developer of the app, instead of allowing them to send arbitrary queries with the app's credentials. This is sometimes relaxed for internal apps that are distributed only to trusted users. For apps that are expected to send large numbers of queries, teams should design a query approval workflow, aligned with the broader software development cycle, to vet queries before they go into production. This ensures that they do not fetch unnecessary data and that server capacity is available to support them. As a second line of defense, estimating the cost of a query before performing it and instituting per-user and per-app query cost budgets can protect against overuse of preregistered operations or in cases where operation preregistration is not possible. Developers should be able to disable the ability of particular apps to send particular queries in production, either as a safety net in emergencies or if a third party app is found to be using the graph in unacceptable ways. 9. Structured Logging Capture structured logs of all graph operations and leverage them as the primary tool for understanding graph usage. A wealth of information can be captured about each operation (read or write) that is performed on a graph: what user and app performed the operation, what fields were accessed, how the operation was actually executed, how it performed, and more. This information is highly valuable and should be systematically captured and made available for later use. Instead of a text log, it should be captured in a structured, machine readable format so that it can be leveraged for as many purposes as possible. The record of a graph operation is called a trace. A trace should bring together all pertinent information about an operation in one place, including business information (who performed the operation, what was accessed or changed, which feature of which app built by which developer, whether it succeeded, how it performed) and purely technical information (which backend services were contacted, how each service contributed to latency, whether caches were used).  Because traces truly capture how a graph is being used, they can be used for a wide range of purposes: Understanding whether a deprecated field can be removed, or if not, the specific clients that are still accessing it and how important they are Predicting how long a query will take to execute – in realtime, as the developer is typing the query in their IDE – based on live production data Automatically detecting problems in production (such as increased latency or error rates) and diagnosing their root cause Providing an authoritative audit trail showing which users have accessed a particular record Powering business intelligence queries (do people search for ice cream more often when it is hot where they are?) Generating invoices for partners based on API usage, with the possibility of a detailed cost model based on either the particular fields accessed or the resources consumed Traces for all graph operations should be collected in one central place, so that there is one authoritative stream of traces. This stream can then be piped into other observability systems (perhaps after a simple transformation for existing systems that are not GraphQL-aware), or stored in one or more data warehouses for later use (aggregated and sampled as budget, use cases, and scale require).  10. Separate the GraphQL Layer from the Service Layer Adopt a layered architecture with graph functionality broken into a separate tier rather than baked into every service. In most API technologies, clients do not talk directly to servers, except possibly in development. Instead, a layered approach is adopted in which some concerns such as load balancing, caching, service location, or API key management are split into a separate tier. This tier can then be designed, operated, and scaled separately from the backend services. It's no different with GraphQL. Rather than baking all of the functionality needed for a complete graph system into each and every service, most graph functionality should be factored out into a separate tier that sits in between clients and services, leaving each service to focus on serving the actual client request. This tier, which can be composed of multiple processes, performs functions such as access and demand control, federation, trace collection, and potentially caching. Some parts of this tier will be GraphQL-specific and require deep awareness of the graph, while other functions such as load balancing and client authentication can likely be performed by systems that are already in place. This separate tier is valuable even in simple scenarios with only one app and only one service; otherwise, functionality that properly belongs in the middle tier will have to be implemented in the server. In complex applications, this tier may start to look like a geographically distributed system: receiving incoming queries through multiple ingress points, processing some of them on the edge of the network with the benefit of edge caches, routing subcomponents of the queries to multiple data centers in the public cloud, privately operated, or operated by partners, and finally assembling these components into a query result, all while recording a trace that memorializes the entire operation. In some cases, this graph tier will talk to the backend services using GraphQL. But, most frequently, the backend services are left untouched and continue to be accessed by their existing APIs, such as REST, SOAP, gRPC, Thrift, or even SQL, with the mapping from these APIs to graph objects accomplished by servers that form one part of the graph tier.","tableOfContents":"<ul>\n<li><a href=\"/principled-graphql/operations/#8-access-and-demand-control\">8. Access and Demand Control</a></li>\n<li><a href=\"/principled-graphql/operations/#9-structured-logging\">9. Structured Logging</a></li>\n<li><a href=\"/principled-graphql/operations/#10-separate-the-graphql-layer-from-the-service-layer\">10. Separate the GraphQL Layer from the Service Layer</a></li>\n</ul>","headings":[{"depth":2,"value":"8. Access and Demand Control"},{"depth":2,"value":"9. Structured Logging"},{"depth":2,"value":"10. Separate the GraphQL Layer from the Service Layer"}],"frontmatter":{"path":"/operations","title":"Operations Principles","description":"Securely deploying the graph to production at scale","order":3,"image":{"publicURL":"/principled-graphql/static/763ec54a971a5ced9b745302e60f5bd3/operations.png"}}}}]},"site":{"siteMetadata":{"title":"Principled GraphQL","description":"Best practices for implementing and scaling a graph"}}},"pageContext":{}}}